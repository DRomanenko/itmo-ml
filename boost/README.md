# [Бустинг](report.ipynb)
### Цели работы:
1. Реализовать алгоритм AdaBoost.
2. Анализ результатов.

### Задание
Изучите и реализуйте алгоритм адаптивного бустинга для задачи классификации с экспоненциальной функцией потерь (AdaBoost). В качестве базового алгоритма используйте дерево решений. Изобразите, как алгоритм классифицирует всё пространство после 1, 2, 3, 5, 8, 13, 21, 34 и 55 шага бустинга. Постройте график зависимости качества от номера шага. В качестве функции качества используйте accuracy.

В данной лабораторной работе также разрешается использовать **sklearn.tree.DecisionTreeClassifier**.

### Наборы данных
Используйте наборы данных [chips.csv](datasets/chips.csv) и [geyser.csv](datasets/geyser.csv) для тестирования вашего классификатора.
